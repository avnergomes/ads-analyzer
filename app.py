<<<<<<< HEAD
"""
Aplicativo Streamlit atualizado para trabalhar com planilha p√∫blica
Mapeamento detalhado e integra√ß√£o com dados de an√∫ncios
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import io
import warnings
from public_sheets_connector import PublicSheetsConnector

warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Ads Analyzer v2.0 - Integra√ß√£o Completa",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
=======
"""Streamlit dashboard for analyzing Meta Ads exports.

The app expects the user to upload up to three CSV exports generated by Meta:
* Days.csv ‚Äì daily performance by ad set.
* Days + Time.csv ‚Äì daily performance broken down by hour of day.
* Days + Placement + Device.csv ‚Äì performance by placement and device.

Every file is normalized so that the same classification pipeline can be applied
regardless of the data source.  The classification rules are maintained in the
`campaign_mapping_fixed.csv` file and use regular expressions to map each ad
into show, funnel, and legacy labels.
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Dict, Iterable, List, Optional

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

# ---------------------------------------------------------------------------
# Streamlit page configuration
# ---------------------------------------------------------------------------
st.set_page_config(page_title="Meta Ads Funnel Analysis", layout="wide")
st.title("üìä Meta Ads Funnel Analysis Dashboard")


# ---------------------------------------------------------------------------
# Mapping configuration
# ---------------------------------------------------------------------------
MAPPING_FILE = Path("campaign_mapping_fixed.csv")

if not MAPPING_FILE.exists():
    st.error("‚ùå Mapping file 'campaign_mapping_fixed.csv' not found in repo.")
    st.stop()

mapping_df = pd.read_csv(MAPPING_FILE).fillna("")


class MappingRule:
    """Lightweight wrapper around a compiled mapping rule."""

    __slots__ = ("compiled", "mapping_type", "mapping_value")

    def __init__(self, pattern: str, mapping_type: str, mapping_value: str) -> None:
        self.compiled = re.compile(pattern, re.IGNORECASE)
        self.mapping_type = mapping_type.lower()
        self.mapping_value = mapping_value.strip()

    def matches(self, text: str) -> bool:
        return bool(self.compiled.search(text))


def build_mapping_rules(table: pd.DataFrame) -> List[MappingRule]:
    """Compile regular expression rules from the mapping table."""

    rules: List[MappingRule] = []
    for _, rule in table.iterrows():
        pattern = str(rule.get("regex_pattern", "")).strip()
        mapping_type = str(rule.get("mapping_type", ""))
        mapping_value = str(rule.get("mapping_value", ""))
        if not pattern:
            # Ignore rows without a usable pattern.
            continue
        try:
            rules.append(MappingRule(pattern, mapping_type, mapping_value))
        except re.error as exc:
            # Skip invalid regular expressions but surface the issue to the UI.
            st.warning(f"‚ö†Ô∏è Invalid regex in mapping file: {pattern!r} ({exc})")
    return rules


MAPPING_RULES = build_mapping_rules(mapping_df)


# ---------------------------------------------------------------------------
# Classification helpers
# ---------------------------------------------------------------------------

CLASSIFICATION_TEXT_FIELDS = (
    "ad_set_name",
    "campaign_name",
    "ad_name",
    "result_type",
    "result_indicator",
    "objective",
    "optimization_goal",
    "optimization_event",
    "campaign_objective",
    "adset_objective",
>>>>>>> parent of 56ea16a (cv01)
)
def normalize_text_parts(row: pd.Series, fields: Iterable[str]) -> str:
    """Concatenate selected fields into a single lowercase string."""

<<<<<<< HEAD
# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-container {
        background: linear-gradient(90deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .metric-value {
        font-size: 2.2rem;
        font-weight: bold;
        color: #1f77b4;
        margin: 0;
    }
    .metric-label {
        font-size: 0.9rem;
        color: #6c757d;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    .status-success {
        color: #28a745;
        font-weight: bold;
    }
    .status-warning {
        color: #ffc107;
        font-weight: bold;
    }
    .status-error {
        color: #dc3545;
        font-weight: bold;
    }
    .data-section {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class AdsDataProcessor:
    """Processador de dados de an√∫ncios com mapeamento inteligente"""
    
    @staticmethod
    def detect_and_normalize_columns(df):
        """
        Detecta e normaliza colunas de dados de an√∫ncios
        """
        if df is None or df.empty:
            return None
        
        # Mapeamento flex√≠vel para diferentes formatos de arquivo
        column_mappings = {
            'date': [
                'date', 'day', 'date_start', 'reporting_starts', 'data', 'fecha',
                'datum', 'created_time', 'campaign_date'
            ],
            'campaign_name': [
                'campaign_name', 'campaign', 'campaign_id', 'campaign_title',
                'nombre_campana', 'campagne', 'kampagne'
            ],
            'impressions': [
                'impressions', 'impression', 'impr', 'views', 'reach',
                'impresiones', 'impressionen', 'show'
            ],
            'clicks': [
                'clicks', 'click', 'link_clicks', 'website_clicks',
                'clics', 'klicks', 'tap'
            ],
            'spend': [
                'spend', 'cost', 'amount_spent', 'investment', 'budget',
                'gasto', 'kosten', 'costo', 'investimento'
            ],
            'conversions': [
                'conversions', 'conversion', 'results', 'actions', 'leads',
                'conversiones', 'konversionen', 'resultados'
            ],
            'ctr': [
                'ctr', 'click_through_rate', 'clickthrough_rate',
                'tasa_clics', 'klickrate'
            ],
            'cpc': [
                'cpc', 'cost_per_click', 'avg_cpc', 'costo_por_clic',
                'kosten_pro_klick'
            ],
            'cpa': [
                'cpa', 'cost_per_acquisition', 'cost_per_action',
                'costo_por_adquisicion', 'kosten_pro_akquisition'
            ],
            'cpm': [
                'cpm', 'cost_per_mille', 'cost_per_1000_impressions',
                'costo_por_mil', 'kosten_pro_tausend'
            ]
        }
        
        # Aplicar mapeamento
        normalized_df = df.copy()
        
        for standard_col, variations in column_mappings.items():
            for col in normalized_df.columns:
                col_clean = col.lower().replace(' ', '_').replace('-', '_')
                if col_clean in [v.lower() for v in variations]:
                    if standard_col not in normalized_df.columns:
                        normalized_df = normalized_df.rename(columns={col: standard_col})
                        break
        
        return normalized_df
    
    @staticmethod
    def calculate_missing_kpis(df):
        """Calcula KPIs que possam estar faltando"""
        if df is None or df.empty:
            return df
        
        # CTR
        if 'ctr' not in df.columns and 'impressions' in df.columns and 'clicks' in df.columns:
            df['ctr'] = np.where(df['impressions'] > 0, 
                               (df['clicks'] / df['impressions']) * 100, 0)
        
        # CPC
        if 'cpc' not in df.columns and 'spend' in df.columns and 'clicks' in df.columns:
            df['cpc'] = np.where(df['clicks'] > 0, 
                               df['spend'] / df['clicks'], 0)
        
        # CPA
        if 'cpa' not in df.columns and 'spend' in df.columns and 'conversions' in df.columns:
            df['cpa'] = np.where(df['conversions'] > 0, 
                               df['spend'] / df['conversions'], 0)
        
        # CPM
        if 'cpm' not in df.columns and 'spend' in df.columns and 'impressions' in df.columns:
            df['cpm'] = np.where(df['impressions'] > 0,
                               (df['spend'] / df['impressions']) * 1000, 0)
        
        # Conversion Rate
        if 'conversion_rate' not in df.columns and 'clicks' in df.columns and 'conversions' in df.columns:
            df['conversion_rate'] = np.where(df['clicks'] > 0,
                                           (df['conversions'] / df['clicks']) * 100, 0)
        
        return df
    
    @staticmethod
    def prepare_for_integration(ads_df, sales_df):
        """
        Prepara dados para integra√ß√£o entre an√∫ncios e vendas
        """
        if ads_df is None or sales_df is None:
            return ads_df, sales_df, {}
        
        integration_mapping = {}
        
        # Criar chaves de integra√ß√£o baseadas em datas
        if 'date' in ads_df.columns and 'show_date' in sales_df.columns:
            # Converter datas para formato comum
            ads_df['integration_date'] = pd.to_datetime(ads_df['date']).dt.date
            sales_df['integration_date'] = pd.to_datetime(sales_df['show_date']).dt.date
            
            integration_mapping['date_range'] = {
                'ads_start': ads_df['integration_date'].min(),
                'ads_end': ads_df['integration_date'].max(),
                'sales_start': sales_df['integration_date'].min(),
                'sales_end': sales_df['integration_date'].max()
            }
        
        # Mapear campanhas para cidades se poss√≠vel
        if 'campaign_name' in ads_df.columns and 'city' in sales_df.columns:
            # Tentar extrair cidade do nome da campanha
            ads_df['extracted_city'] = ads_df['campaign_name'].str.extract(r'([A-Za-z\s]+)', expand=False)
            
            unique_cities = sales_df['city'].dropna().unique()
            unique_campaigns = ads_df['campaign_name'].dropna().unique()
            
            integration_mapping['city_campaign_mapping'] = {
                'cities_in_sales': unique_cities.tolist(),
                'campaigns_in_ads': unique_campaigns.tolist()
            }
        
        return ads_df, sales_df, integration_mapping

class IntegratedDashboard:
    """Dashboard integrado para an√°lise completa"""
    
    def __init__(self):
        self.sales_data = None
        self.ads_data = None
        self.integration_mapping = {}
    
    def create_sales_overview(self, df):
        """Cria vis√£o geral dos dados de vendas"""
        if df is None or df.empty:
            st.warning("üìä Nenhum dado de vendas dispon√≠vel")
            return
        
        st.subheader("üé´ Vis√£o Geral das Vendas")
        
        # M√©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_shows = len(df)
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Total de Shows</div>
                <div class="metric-value">{total_shows:,}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            total_capacity = df['capacity'].sum() if 'capacity' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Capacidade Total</div>
                <div class="metric-value">{total_capacity:,}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            total_sold = df['total_sold'].sum() if 'total_sold' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Total Vendido</div>
                <div class="metric-value">{total_sold:,}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            total_revenue = df['sales_to_date'].sum() if 'sales_to_date' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Receita Total</div>
                <div class="metric-value">R$ {total_revenue:,.0f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        # M√©tricas secund√°rias
        col5, col6, col7, col8 = st.columns(4)
        
        with col5:
            avg_occupancy = df['occupancy_rate'].mean() if 'occupancy_rate' in df.columns else 0
            color_class = "status-success" if avg_occupancy >= 80 else "status-warning" if avg_occupancy >= 60 else "status-error"
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Ocupa√ß√£o M√©dia</div>
                <div class="metric-value {color_class}">{avg_occupancy:.1f}%</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col6:
            avg_ticket = df['avg_ticket_price'].mean() if 'avg_ticket_price' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Ticket M√©dio</div>
                <div class="metric-value">R$ {avg_ticket:.0f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col7:
            cities_count = df['city'].nunique() if 'city' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Cidades</div>
                <div class="metric-value">{cities_count}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col8:
            sold_out_shows = len(df[df['occupancy_rate'] >= 99]) if 'occupancy_rate' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Shows Esgotados</div>
                <div class="metric-value">{sold_out_shows}</div>
            </div>
            """, unsafe_allow_html=True)
    
    def create_sales_charts(self, df):
        """Cria gr√°ficos de vendas"""
        if df is None or df.empty:
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìà Performance por Cidade**")
            if 'city' in df.columns and 'total_sold' in df.columns:
                city_performance = df.groupby('city').agg({
                    'total_sold': 'sum',
                    'capacity': 'sum',
                    'sales_to_date': 'sum'
                }).reset_index()
                
                city_performance['occupancy'] = (city_performance['total_sold'] / city_performance['capacity']) * 100
                city_performance = city_performance.sort_values('total_sold', ascending=True)
                
                fig = px.bar(city_performance.tail(10), 
                           x='total_sold', y='city', 
                           orientation='h',
                           color='occupancy',
                           color_continuous_scale='RdYlGn',
                           title="Top 10 Cidades por Vendas")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("**üéØ Distribui√ß√£o de Ocupa√ß√£o**")
            if 'occupancy_rate' in df.columns:
                fig = px.histogram(df, x='occupancy_rate', 
                                 nbins=20,
                                 title="Distribui√ß√£o de Taxa de Ocupa√ß√£o",
                                 color_discrete_sequence=['#1f77b4'])
                fig.update_layout(height=400)
                fig.update_xaxis(title="Taxa de Ocupa√ß√£o (%)")
                fig.update_yaxis(title="N√∫mero de Shows")
                st.plotly_chart(fig, use_container_width=True)
        
        # Gr√°fico de linha temporal
        if 'show_date' in df.columns and df['show_date'].notna().any():
            st.markdown("**üìÖ Vendas ao Longo do Tempo**")
            
            daily_sales = df.groupby('show_date').agg({
                'today_sold': 'sum',
                'sales_to_date': 'sum',
                'total_sold': 'sum'
            }).reset_index()
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=daily_sales['show_date'],
                y=daily_sales['total_sold'],
                mode='lines+markers',
                name='Total Vendido',
                line=dict(color='#1f77b4', width=2)
            ))
            
            fig.add_trace(go.Scatter(
                x=daily_sales['show_date'],
                y=daily_sales['today_sold'],
                mode='lines+markers',
                name='Vendas do Dia',
                line=dict(color='#ff7f0e', width=2)
            ))
            
            fig.update_layout(
                title="Evolu√ß√£o das Vendas por Data",
                xaxis_title="Data do Show",
                yaxis_title="Quantidade de Ingressos",
                height=400,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    def create_ads_overview(self, df):
        """Cria vis√£o geral dos dados de an√∫ncios"""
        if df is None or df.empty:
            st.warning("üìä Nenhum dado de an√∫ncios dispon√≠vel")
            return
        
        st.subheader("üìà Vis√£o Geral dos An√∫ncios")
        
        # M√©tricas principais de an√∫ncios
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_impressions = df['impressions'].sum() if 'impressions' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Impress√µes</div>
                <div class="metric-value">{total_impressions:,}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            total_clicks = df['clicks'].sum() if 'clicks' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Clicks</div>
                <div class="metric-value">{total_clicks:,}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            total_spend = df['spend'].sum() if 'spend' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Investimento</div>
                <div class="metric-value">R$ {total_spend:,.2f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            total_conversions = df['conversions'].sum() if 'conversions' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Convers√µes</div>
                <div class="metric-value">{total_conversions:,}</div>
            </div>
            """, unsafe_allow_html=True)
        
        # KPIs calculados
        col5, col6, col7, col8 = st.columns(4)
        
        with col5:
            avg_ctr = df['ctr'].mean() if 'ctr' in df.columns else 0
            color_class = "status-success" if avg_ctr >= 2 else "status-warning" if avg_ctr >= 1 else "status-error"
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">CTR M√©dio</div>
                <div class="metric-value {color_class}">{avg_ctr:.2f}%</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col6:
            avg_cpc = df['cpc'].mean() if 'cpc' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">CPC M√©dio</div>
                <div class="metric-value">R$ {avg_cpc:.2f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col7:
            avg_cpa = df['cpa'].mean() if 'cpa' in df.columns else 0
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">CPA M√©dio</div>
                <div class="metric-value">R$ {avg_cpa:.2f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col8:
            conversion_rate = df['conversion_rate'].mean() if 'conversion_rate' in df.columns else 0
            color_class = "status-success" if conversion_rate >= 5 else "status-warning" if conversion_rate >= 2 else "status-error"
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Taxa Convers√£o</div>
                <div class="metric-value {color_class}">{conversion_rate:.2f}%</div>
            </div>
            """, unsafe_allow_html=True)
    
    def create_ads_charts(self, df):
        """Cria gr√°ficos de an√∫ncios"""
        if df is None or df.empty:
            return
        
        # Funil de convers√£o
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üéØ Funil de Convers√£o**")
            
            funnel_data = []
            if 'impressions' in df.columns:
                funnel_data.append(['Impress√µes', df['impressions'].sum()])
            if 'clicks' in df.columns:
                funnel_data.append(['Clicks', df['clicks'].sum()])
            if 'conversions' in df.columns:
                funnel_data.append(['Convers√µes', df['conversions'].sum()])
            
            if len(funnel_data) >= 2:
                labels, values = zip(*funnel_data)
                
                fig = go.Figure(go.Funnel(
                    y=labels,
                    x=values,
                    textinfo="value+percent initial+percent previous",
                    marker=dict(color=["#1f77b4", "#ff7f0e", "#2ca02c"][:len(labels)])
                ))
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("**üìä Performance por Campanha**")
            
            if 'campaign_name' in df.columns:
                campaign_performance = df.groupby('campaign_name').agg({
                    'impressions': 'sum',
                    'clicks': 'sum',
                    'spend': 'sum',
                    'conversions': 'sum'
                }).reset_index()
                
                campaign_performance['ctr'] = np.where(
                    campaign_performance['impressions'] > 0,
                    (campaign_performance['clicks'] / campaign_performance['impressions']) * 100,
                    0
                )
                
                fig = px.scatter(campaign_performance,
                               x='spend', y='conversions',
                               size='clicks',
                               color='ctr',
                               hover_data=['campaign_name'],
                               title="Investimento vs Convers√µes por Campanha",
                               color_continuous_scale='RdYlGn')
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
        
        # Tend√™ncia temporal
        if 'date' in df.columns and df['date'].notna().any():
            st.markdown("**üìà Tend√™ncia Temporal**")
            
            daily_ads = df.groupby('date').agg({
                'impressions': 'sum',
                'clicks': 'sum',
                'spend': 'sum',
                'conversions': 'sum'
            }).reset_index()
            
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=['Impress√µes', 'Clicks', 'Investimento', 'Convers√µes']
            )
            
            fig.add_trace(
                go.Scatter(x=daily_ads['date'], y=daily_ads['impressions'],
                         name='Impress√µes', line=dict(color='#1f77b4')),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=daily_ads['date'], y=daily_ads['clicks'],
                         name='Clicks', line=dict(color='#ff7f0e')),
                row=1, col=2
            )
            
            fig.add_trace(
                go.Scatter(x=daily_ads['date'], y=daily_ads['spend'],
                         name='Investimento', line=dict(color='#2ca02c')),
                row=2, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=daily_ads['date'], y=daily_ads['conversions'],
                         name='Convers√µes', line=dict(color='#d62728')),
                row=2, col=2
            )
            
            fig.update_layout(height=500, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
    
    def create_integration_analysis(self, sales_df, ads_df, mapping):
        """Cria an√°lise integrada entre vendas e an√∫ncios"""
        if sales_df is None or ads_df is None:
            return
        
        st.subheader("üîó An√°lise Integrada")
        
        # Verificar sobreposi√ß√£o de datas
        if 'integration_date' in sales_df.columns and 'integration_date' in ads_df.columns:
            
            sales_dates = set(sales_df['integration_date'].dropna())
            ads_dates = set(ads_df['integration_date'].dropna())
            overlap_dates = sales_dates.intersection(ads_dates)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-label">Datas com Vendas</div>
                    <div class="metric-value">{len(sales_dates)}</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-label">Datas com An√∫ncios</div>
                    <div class="metric-value">{len(ads_dates)}</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                overlap_pct = (len(overlap_dates) / max(len(sales_dates), 1)) * 100
                color_class = "status-success" if overlap_pct >= 70 else "status-warning" if overlap_pct >= 40 else "status-error"
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-label">Sobreposi√ß√£o</div>
                    <div class="metric-value {color_class}">{overlap_pct:.1f}%</div>
                </div>
                """, unsafe_allow_html=True)
            
            # An√°lise de correla√ß√£o por data
            if len(overlap_dates) > 0:
                # Agregar dados por data
                sales_by_date = sales_df.groupby('integration_date').agg({
                    'total_sold': 'sum',
                    'sales_to_date': 'sum'
                }).reset_index()
                
                ads_by_date = ads_df.groupby('integration_date').agg({
                    'impressions': 'sum',
                    'clicks': 'sum',
                    'spend': 'sum',
                    'conversions': 'sum'
                }).reset_index()
                
                # Fazer merge
                integrated_data = pd.merge(
                    sales_by_date, ads_by_date, 
                    on='integration_date', 
                    how='inner'
                )
                
                if not integrated_data.empty:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**üìä Investimento vs Vendas**")
                        fig = px.scatter(
                            integrated_data,
                            x='spend', y='total_sold',
                            size='impressions',
                            color='clicks',
                            hover_data=['integration_date'],
                            title="Correla√ß√£o: Investimento em An√∫ncios vs Vendas",
                            trendline="ols"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        st.markdown("**üéØ Impress√µes vs Receita**")
                        fig = px.scatter(
                            integrated_data,
                            x='impressions', y='sales_to_date',
                            size='clicks',
                            color='spend',
                            hover_data=['integration_date'],
                            title="Correla√ß√£o: Impress√µes vs Receita",
                            trendline="ols"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Calcular correla√ß√µes
                    st.markdown("**üìà Correla√ß√µes**")
                    
                    correlations = {
                        'Investimento vs Vendas': integrated_data['spend'].corr(integrated_data['total_sold']),
                        'Impress√µes vs Vendas': integrated_data['impressions'].corr(integrated_data['total_sold']),
                        'Clicks vs Vendas': integrated_data['clicks'].corr(integrated_data['total_sold']),
                        'Investimento vs Receita': integrated_data['spend'].corr(integrated_data['sales_to_date'])
                    }
                    
                    corr_df = pd.DataFrame(list(correlations.items()), columns=['M√©trica', 'Correla√ß√£o'])
                    corr_df['Correla√ß√£o'] = corr_df['Correla√ß√£o'].round(3)
                    corr_df['For√ßa'] = corr_df['Correla√ß√£o'].apply(
                        lambda x: 'Forte' if abs(x) >= 0.7 else 'Moderada' if abs(x) >= 0.4 else 'Fraca'
                    )
                    
                    st.dataframe(corr_df, use_container_width=True)

def main():
    """Fun√ß√£o principal do aplicativo"""
    
    # Cabe√ßalho
    st.markdown('<h1 class="main-header">üìä Ads Analyzer v2.0</h1>', unsafe_allow_html=True)
    st.markdown("*An√°lise integrada de performance de an√∫ncios e dados de vendas com mapeamento detalhado*")
    
    # Sidebar
    st.sidebar.header("‚öôÔ∏è Configura√ß√µes")
    
    # Inicializar conectores e processadores
    sheets_connector = PublicSheetsConnector()
    ads_processor = AdsDataProcessor()
    dashboard = IntegratedDashboard()
    
    # Se√ß√£o 1: Dados de Vendas (Google Sheets P√∫blico)
    st.sidebar.subheader("üìä Dados de Vendas")
    
    load_sales = st.sidebar.button("üîÑ Carregar Dados de Vendas", key="load_sales")
    
    if load_sales or 'sales_data' not in st.session_state:
        with st.spinner("Carregando dados de vendas..."):
            sales_data = sheets_connector.load_data()
            if sales_data is not None:
                st.session_state.sales_data = sales_data
                st.sidebar.success(f"‚úÖ {len(sales_data)} shows carregados")
                
                # Mostrar resumo dos dados
                summary = sheets_connector.get_data_summary(sales_data)
                st.sidebar.info(f"üìà Ocupa√ß√£o m√©dia: {summary.get('avg_occupancy', 0):.1f}%")
                st.sidebar.info(f"üèôÔ∏è {summary.get('unique_cities', 0)} cidades")
            else:
                st.sidebar.error("‚ùå Erro ao carregar dados")
                st.session_state.sales_data = None
    
    # Se√ß√£o 2: Dados de An√∫ncios
    st.sidebar.subheader("üìà Dados de An√∫ncios")
    
    ads_file = st.sidebar.file_uploader(
        "Upload dos dados de an√∫ncios",
        type=['csv', 'xlsx', 'xls'],
        help="Arquivo com dados de performance de an√∫ncios (Meta, Google, etc.)"
    )
    
    if ads_file:
        try:
            # Carregar arquivo
            if ads_file.name.endswith('.csv'):
                ads_data = pd.read_csv(ads_file)
            else:
                ads_data = pd.read_excel(ads_file)
            
            # Processar dados
            ads_data = ads_processor.detect_and_normalize_columns(ads_data)
            ads_data = ads_processor.calculate_missing_kpis(ads_data)
            
            st.session_state.ads_data = ads_data
            st.sidebar.success(f"‚úÖ {len(ads_data)} registros de an√∫ncios carregados")
            
        except Exception as e:
            st.sidebar.error(f"‚ùå Erro ao processar arquivo: {str(e)}")
            st.session_state.ads_data = None
    
    # Dashboard principal
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Vendas", "üìà An√∫ncios", "üîó Integra√ß√£o", "üîç Dados Brutos"])
    
    with tab1:
        if 'sales_data' in st.session_state and st.session_state.sales_data is not None:
            dashboard.create_sales_overview(st.session_state.sales_data)
            st.markdown("---")
            dashboard.create_sales_charts(st.session_state.sales_data)
        else:
            st.info("üëÜ Carregue os dados de vendas usando o bot√£o na barra lateral")
    
    with tab2:
        if 'ads_data' in st.session_state and st.session_state.ads_data is not None:
            dashboard.create_ads_overview(st.session_state.ads_data)
            st.markdown("---")
            dashboard.create_ads_charts(st.session_state.ads_data)
        else:
            st.info("üëÜ Fa√ßa upload dos dados de an√∫ncios usando a barra lateral")
    
    with tab3:
        sales_df = st.session_state.get('sales_data')
        ads_df = st.session_state.get('ads_data')
        
        if sales_df is not None and ads_df is not None:
            # Preparar dados para integra√ß√£o
            ads_df, sales_df, mapping = ads_processor.prepare_for_integration(ads_df, sales_df)
            dashboard.create_integration_analysis(sales_df, ads_df, mapping)
        else:
            st.info("üëÜ Carregue tanto os dados de vendas quanto os dados de an√∫ncios para ver a an√°lise integrada")
    
    with tab4:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üé´ Dados de Vendas")
            if 'sales_data' in st.session_state and st.session_state.sales_data is not None:
                st.dataframe(st.session_state.sales_data, use_container_width=True)
                
                # Op√ß√£o de download
                csv = st.session_state.sales_data.to_csv(index=False)
                st.download_button(
                    "üì• Download CSV - Vendas",
                    csv,
                    "sales_data.csv",
                    "text/csv"
                )
            else:
                st.info("Nenhum dado de vendas carregado")
        
        with col2:
            st.subheader("üìà Dados de An√∫ncios")
            if 'ads_data' in st.session_state and st.session_state.ads_data is not None:
                st.dataframe(st.session_state.ads_data, use_container_width=True)
                
                # Op√ß√£o de download
                csv = st.session_state.ads_data.to_csv(index=False)
                st.download_button(
                    "üì• Download CSV - An√∫ncios",
                    csv,
                    "ads_data.csv",
                    "text/csv"
                )
            else:
                st.info("Nenhum dado de an√∫ncios carregado")
    
    # Footer
    st.markdown("---")
    st.markdown("*Desenvolvido com ‚ù§Ô∏è usando Streamlit | Ads Analyzer v2.0 - Integra√ß√£o Completa*")
=======
    parts: List[str] = []
    for field in fields:
        value = row.get(field)
        if pd.notna(value) and str(value).strip():
            parts.append(str(value).lower())
    return " ".join(parts)


def apply_classification(row: pd.Series) -> pd.Series:
    """Return a Series with classification fields derived from mapping rules."""

    text = normalize_text_parts(row, CLASSIFICATION_TEXT_FIELDS)

    show: Optional[str] = None
    funnel: Optional[str] = None
    legacy_labels: List[str] = []

    for rule in MAPPING_RULES:
        if not text or not rule.matches(text):
            continue
        if rule.mapping_type == "show" and not show:
            show = rule.mapping_value or "Unknown"
        elif rule.mapping_type == "funnel" and not funnel:
            value = rule.mapping_value
            funnel = value if value.lower().startswith("funnel") else f"Funnel {value}"
        elif rule.mapping_type == "legacy" and rule.mapping_value:
            legacy_labels.append(rule.mapping_value)

    # Fallbacks keep the dashboard consistent even when no rule matches.
    show = show or "Unknown"
    funnel = funnel or "Unclassified"
    legacy = ", ".join(sorted(set(legacy_labels))) if legacy_labels else None

    readable_labels = [
        label
        for label in (show if show != "Unknown" else None,
                      funnel if funnel != "Unclassified" else None,
                      legacy)
        if label
    ]
    classification = " | ".join(readable_labels) if readable_labels else "Unclassified"

    return pd.Series(
        {
            "classification": classification,
            "funnel": funnel,
            "show": show,
            "legacy_label": legacy,
        }
    )


# ---------------------------------------------------------------------------
# Data wrangling helpers
# ---------------------------------------------------------------------------
NUMERIC_CANDIDATES = [
    "amount_spent_(usd)",
    "impressions",
    "results",
    "cost_per_results",
    "clicks",
    "cpm",
    "ctr_(link_click-through_rate)",
]


def sanitize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Normalize column names and convert numeric fields where possible."""

    renamed = {
        col: col.strip().lower().replace(" ", "_").replace("/", "_per_")
        for col in df.columns
    }
    df = df.rename(columns=renamed)

    for col in NUMERIC_CANDIDATES:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    if "reporting_starts" in df.columns:
        df["reporting_starts"] = pd.to_datetime(df["reporting_starts"], errors="coerce")

    return df


def parse_hour(value: object) -> Optional[int]:
    """Extract the starting hour from Meta's "0:00 - 1:00" time slots."""

    if pd.isna(value):
        return None
    text = str(value).strip()
    match = re.search(r"\b(\d{1,2})", text)
    if not match:
        return None
    hour = int(match.group(1))
    return hour % 24


def compute_decay(df: pd.DataFrame) -> pd.DataFrame:
    """Estimate how many consecutive good days each ad set produced."""

    if "ad_set_name" not in df.columns or "cost_per_results" not in df.columns:
        return pd.DataFrame()

    results: List[Dict[str, object]] = []
    grouped = df.sort_values("reporting_starts").groupby("ad_set_name", dropna=True)

    for adset, group in grouped:
        group = group.copy()
        baseline = (
            group["cost_per_results"].replace([np.inf, -np.inf], np.nan).dropna().head(3).median()
        )
        if pd.isna(baseline) or baseline <= 0:
            continue

        group["is_good"] = group["cost_per_results"] <= 1.3 * baseline
        good_days = 0
        bad_streak = 0

        for is_good in group["is_good"]:
            if is_good:
                good_days += 1
                bad_streak = 0
            else:
                bad_streak += 1
                if bad_streak >= 3:
                    break

        funnel_value = group["funnel"].iloc[0] if "funnel" in group else "Unclassified"
        show_value = group["show"].iloc[0] if "show" in group else "Unknown"

        results.append(
            {
                "ad_set_name": adset,
                "funnel": funnel_value,
                "show": show_value,
                "good_days_before_drop": good_days,
            }
        )

    return pd.DataFrame(results)


# ---------------------------------------------------------------------------
# File upload handling
# ---------------------------------------------------------------------------
st.sidebar.header("Upload your Meta CSV exports")
days_file = st.sidebar.file_uploader("Days.csv", type="csv")
days_time_file = st.sidebar.file_uploader("Days + Time.csv", type="csv")
days_pd_file = st.sidebar.file_uploader("Days + Placement + Device.csv", type="csv")


def load_csv(upload: Optional[st.runtime.uploaded_file_manager.UploadedFile], name: str,
             store: Dict[str, pd.DataFrame]) -> None:
    """Read a user supplied CSV, sanitize columns, and apply classification."""

    if upload is None:
        return

    try:
        df = pd.read_csv(upload)
    except UnicodeDecodeError:
        df = pd.read_csv(upload, encoding="latin1")

    df = sanitize_columns(df)
    classification = df.apply(apply_classification, axis=1)
    for col in classification.columns:
        df[col] = classification[col]

    store[name] = df

>>>>>>> parent of 56ea16a (cv01)

uploaded_dfs: Dict[str, pd.DataFrame] = {}
load_csv(days_file, "days", uploaded_dfs)
load_csv(days_time_file, "days_time", uploaded_dfs)
load_csv(days_pd_file, "days_pd", uploaded_dfs)

if not uploaded_dfs:
    st.info("‚¨ÜÔ∏è Please upload at least one Meta Ads export file to start.")
    st.stop()


# ---------------------------------------------------------------------------
# Analysis sections
# ---------------------------------------------------------------------------
def render_funnel_decay(days_df: pd.DataFrame) -> None:
    """Render distribution of good days per funnel."""

    st.subheader("‚è≥ Funnel Decay Analysis")
    decay_df = compute_decay(days_df)
    if decay_df.empty:
        st.info("Not enough data to compute funnel decay.")
        return

    fig = px.box(
        decay_df,
        x="funnel",
        y="good_days_before_drop",
        title="Distribution of Good Days Before Drop by Funnel",
        points="all",
        color="funnel",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(decay_df.groupby("funnel")["good_days_before_drop"].describe())


def render_show_funnel_overview(days_df: pd.DataFrame) -> None:
    """Show spend and results by show and funnel."""

    st.subheader("üåç Show √ó Funnel Overview")
    required = {"funnel", "show", "amount_spent_(usd)", "impressions", "results", "cost_per_results"}
    if not required.issubset(days_df.columns):
        st.warning("Some required columns are missing from Days.csv export.")
        return

    overview = (
        days_df.groupby(["show", "funnel"]).agg(
            spend=("amount_spent_(usd)", "sum"),
            impressions=("impressions", "sum"),
            results=("results", "sum"),
            avg_cpr=("cost_per_results", "mean"),
        )
        .reset_index()
    )

    fig = px.scatter(
        overview,
        x="spend",
        y="results",
        size="impressions",
        color="funnel",
        facet_col="show",
        hover_data=["avg_cpr"],
        title="Spend vs Results by Show & Funnel",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(overview)


def render_time_of_day(days_time_df: pd.DataFrame) -> None:
    """Plot average cost per result by hour for each funnel."""

    st.subheader("üïí Time-of-Day Performance")
    if "time_of_day_(viewer's_time_zone)" not in days_time_df.columns or "cost_per_results" not in days_time_df.columns:
        st.info("No valid time-of-day data available.")
        return

    temp = days_time_df.copy()
    temp["hour"] = temp["time_of_day_(viewer's_time_zone)"].apply(parse_hour)
    if "funnel" not in temp.columns:
        temp["funnel"] = "Unclassified"

    def weighted_avg(group: pd.DataFrame) -> float:
        if "results" in group.columns and group["results"].sum() > 0:
            return float(np.average(group["cost_per_results"], weights=group["results"]))
        return float(group["cost_per_results"].mean())

    hour_perf = temp.groupby(["funnel", "hour"], dropna=True).apply(weighted_avg).reset_index(name="avg_cpr")
    if hour_perf.empty:
        st.info("Unable to calculate time-of-day metrics for the uploaded file.")
        return

    funnel_sel = st.selectbox("Funnel (Time)", sorted(hour_perf["funnel"].unique()))
    filtered = hour_perf[hour_perf["funnel"] == funnel_sel]

    fig = px.line(
        filtered,
        x="hour",
        y="avg_cpr",
        markers=True,
        title=f"Avg Cost per Result by Hour ({funnel_sel})",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(filtered)


def render_placement(days_pd_df: pd.DataFrame) -> None:
    """Evaluate placement performance within each funnel."""

    st.subheader("üì± Placement Performance")
    required = {"placement", "cost_per_results", "results", "amount_spent_(usd)", "funnel"}
    if not required.issubset(days_pd_df.columns):
        st.warning("Placement columns not found in Days + Placement + Device export.")
        return

    placement_perf = (
        days_pd_df.groupby(["funnel", "placement"]).agg(
            avg_cpr=("cost_per_results", "mean"),
            results=("results", "sum"),
            spend=("amount_spent_(usd)", "sum"),
        )
        .reset_index()
    )

    funnel_sel = st.selectbox("Funnel (Placement)", sorted(placement_perf["funnel"].unique()))
    filtered = placement_perf[placement_perf["funnel"] == funnel_sel]

    fig = px.bar(
        filtered.sort_values("avg_cpr"),
        x="placement",
        y="avg_cpr",
        color="spend",
        text="results",
        title=f"Placement Efficiency ({funnel_sel})",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(filtered)


def render_device(days_pd_df: pd.DataFrame) -> None:
    """Compare device performance within each funnel."""

    st.subheader("üíª Device Performance")
    required = {"impression_device", "cost_per_results", "results", "amount_spent_(usd)", "funnel"}
    if not required.issubset(days_pd_df.columns):
        st.warning("Device columns not found in Days + Placement + Device export.")
        return

    device_perf = (
        days_pd_df.groupby(["funnel", "impression_device"]).agg(
            avg_cpr=("cost_per_results", "mean"),
            results=("results", "sum"),
            spend=("amount_spent_(usd)", "sum"),
        )
        .reset_index()
    )

    funnel_sel = st.selectbox("Funnel (Device)", sorted(device_perf["funnel"].unique()))
    filtered = device_perf[device_perf["funnel"] == funnel_sel]

    fig = px.bar(
        filtered.sort_values("avg_cpr"),
        x="impression_device",
        y="avg_cpr",
        color="spend",
        text="results",
        title=f"Device Efficiency ({funnel_sel})",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(filtered)


# Trigger the different dashboard sections based on available uploads.
days_df = uploaded_dfs.get("days")
days_time_df = uploaded_dfs.get("days_time")
days_pd_df = uploaded_dfs.get("days_pd")

if days_df is not None:
    render_funnel_decay(days_df)
    render_show_funnel_overview(days_df)

if days_time_df is not None:
    render_time_of_day(days_time_df)

if days_pd_df is not None:
    render_placement(days_pd_df)
    render_device(days_pd_df)

st.success("‚úÖ Analyses complete. Explore interactively!")
