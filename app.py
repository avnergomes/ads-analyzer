"""Streamlit dashboard for analyzing Meta Ads exports.

The app expects the user to upload up to three CSV exports generated by Meta:
* Days.csv ‚Äì daily performance by ad set.
* Days + Time.csv ‚Äì daily performance broken down by hour of day.
* Days + Placement + Device.csv ‚Äì performance by placement and device.

Every file is normalized so that the same classification pipeline can be applied
regardless of the data source.  The classification rules are maintained in the
`campaign_mapping_fixed.csv` file and use regular expressions to map each ad
into show, funnel, and legacy labels.
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Dict, Iterable, List, Optional

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

# ---------------------------------------------------------------------------
# Streamlit page configuration
# ---------------------------------------------------------------------------
st.set_page_config(page_title="Meta Ads Funnel Analysis", layout="wide")
st.title("üìä Meta Ads Funnel Analysis Dashboard")


# ---------------------------------------------------------------------------
# Mapping configuration
# ---------------------------------------------------------------------------
MAPPING_FILE = Path("campaign_mapping_fixed.csv")

if not MAPPING_FILE.exists():
    st.error("‚ùå Mapping file 'campaign_mapping_fixed.csv' not found in repo.")
    st.stop()

mapping_df = pd.read_csv(MAPPING_FILE).fillna("")


class MappingRule:
    """Lightweight wrapper around a compiled mapping rule."""

    __slots__ = ("compiled", "mapping_type", "mapping_value")

    def __init__(self, pattern: str, mapping_type: str, mapping_value: str) -> None:
        self.compiled = re.compile(pattern, re.IGNORECASE)
        self.mapping_type = mapping_type.lower()
        self.mapping_value = mapping_value.strip()

    def matches(self, text: str) -> bool:
        return bool(self.compiled.search(text))


def build_mapping_rules(table: pd.DataFrame) -> List[MappingRule]:
    """Compile regular expression rules from the mapping table."""

    rules: List[MappingRule] = []
    for _, rule in table.iterrows():
        pattern = str(rule.get("regex_pattern", "")).strip()
        mapping_type = str(rule.get("mapping_type", ""))
        mapping_value = str(rule.get("mapping_value", ""))
        if not pattern:
            # Ignore rows without a usable pattern.
            continue
        try:
            rules.append(MappingRule(pattern, mapping_type, mapping_value))
        except re.error as exc:
            # Skip invalid regular expressions but surface the issue to the UI.
            st.warning(f"‚ö†Ô∏è Invalid regex in mapping file: {pattern!r} ({exc})")
    return rules


MAPPING_RULES = build_mapping_rules(mapping_df)


# ---------------------------------------------------------------------------
# Classification helpers
# ---------------------------------------------------------------------------

CLASSIFICATION_TEXT_FIELDS = (
    "ad_set_name",
    "campaign_name",
    "ad_name",
    "result_type",
    "result_indicator",
    "objective",
    "optimization_goal",
    "optimization_event",
    "campaign_objective",
    "adset_objective",
)
def normalize_text_parts(row: pd.Series, fields: Iterable[str]) -> str:
    """Concatenate selected fields into a single lowercase string."""

    parts: List[str] = []
    for field in fields:
        value = row.get(field)
        if pd.notna(value) and str(value).strip():
            parts.append(str(value).lower())
    return " ".join(parts)


def apply_classification(row: pd.Series) -> pd.Series:
    """Return a Series with classification fields derived from mapping rules."""

    text = normalize_text_parts(row, CLASSIFICATION_TEXT_FIELDS)

    show: Optional[str] = None
    funnel: Optional[str] = None
    legacy_labels: List[str] = []

    for rule in MAPPING_RULES:
        if not text or not rule.matches(text):
            continue
        if rule.mapping_type == "show" and not show:
            show = rule.mapping_value or "Unknown"
        elif rule.mapping_type == "funnel" and not funnel:
            value = rule.mapping_value
            funnel = value if value.lower().startswith("funnel") else f"Funnel {value}"
        elif rule.mapping_type == "legacy" and rule.mapping_value:
            legacy_labels.append(rule.mapping_value)

    # Fallbacks keep the dashboard consistent even when no rule matches.
    show = show or "Unknown"
    funnel = funnel or "Unclassified"
    legacy = ", ".join(sorted(set(legacy_labels))) if legacy_labels else None

    readable_labels = [
        label
        for label in (show if show != "Unknown" else None,
                      funnel if funnel != "Unclassified" else None,
                      legacy)
        if label
    ]
    classification = " | ".join(readable_labels) if readable_labels else "Unclassified"

    return pd.Series(
        {
            "classification": classification,
            "funnel": funnel,
            "show": show,
            "legacy_label": legacy,
        }
    )


# ---------------------------------------------------------------------------
# Data wrangling helpers
# ---------------------------------------------------------------------------
NUMERIC_CANDIDATES = [
    "amount_spent_(usd)",
    "impressions",
    "results",
    "cost_per_results",
    "clicks",
    "cpm",
    "ctr_(link_click-through_rate)",
]


def sanitize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Normalize column names and convert numeric fields where possible."""

    renamed = {
        col: col.strip().lower().replace(" ", "_").replace("/", "_per_")
        for col in df.columns
    }
    df = df.rename(columns=renamed)

    for col in NUMERIC_CANDIDATES:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    if "reporting_starts" in df.columns:
        df["reporting_starts"] = pd.to_datetime(df["reporting_starts"], errors="coerce")

    return df


def parse_hour(value: object) -> Optional[int]:
    """Extract the starting hour from Meta's "0:00 - 1:00" time slots."""

    if pd.isna(value):
        return None
    text = str(value).strip()
    match = re.search(r"\b(\d{1,2})", text)
    if not match:
        return None
    hour = int(match.group(1))
    return hour % 24


def compute_decay(df: pd.DataFrame) -> pd.DataFrame:
    """Estimate how many consecutive good days each ad set produced."""

    if "ad_set_name" not in df.columns or "cost_per_results" not in df.columns:
        return pd.DataFrame()

    results: List[Dict[str, object]] = []
    grouped = df.sort_values("reporting_starts").groupby("ad_set_name", dropna=True)

    for adset, group in grouped:
        group = group.copy()
        baseline = (
            group["cost_per_results"].replace([np.inf, -np.inf], np.nan).dropna().head(3).median()
        )
        if pd.isna(baseline) or baseline <= 0:
            continue

        group["is_good"] = group["cost_per_results"] <= 1.3 * baseline
        good_days = 0
        bad_streak = 0

        for is_good in group["is_good"]:
            if is_good:
                good_days += 1
                bad_streak = 0
            else:
                bad_streak += 1
                if bad_streak >= 3:
                    break

        funnel_value = group["funnel"].iloc[0] if "funnel" in group else "Unclassified"
        show_value = group["show"].iloc[0] if "show" in group else "Unknown"

        results.append(
            {
                "ad_set_name": adset,
                "funnel": funnel_value,
                "show": show_value,
                "good_days_before_drop": good_days,
            }
        )

    return pd.DataFrame(results)


# ---------------------------------------------------------------------------
# File upload handling
# ---------------------------------------------------------------------------
st.sidebar.header("Upload your Meta CSV exports")
days_file = st.sidebar.file_uploader("Days.csv", type="csv")
days_time_file = st.sidebar.file_uploader("Days + Time.csv", type="csv")
days_pd_file = st.sidebar.file_uploader("Days + Placement + Device.csv", type="csv")


def load_csv(upload: Optional[st.runtime.uploaded_file_manager.UploadedFile], name: str,
             store: Dict[str, pd.DataFrame]) -> None:
    """Read a user supplied CSV, sanitize columns, and apply classification."""

    if upload is None:
        return

    try:
        df = pd.read_csv(upload)
    except UnicodeDecodeError:
        df = pd.read_csv(upload, encoding="latin1")

    df = sanitize_columns(df)
    classification = df.apply(apply_classification, axis=1)
    for col in classification.columns:
        df[col] = classification[col]

    store[name] = df


uploaded_dfs: Dict[str, pd.DataFrame] = {}
load_csv(days_file, "days", uploaded_dfs)
load_csv(days_time_file, "days_time", uploaded_dfs)
load_csv(days_pd_file, "days_pd", uploaded_dfs)

if not uploaded_dfs:
    st.info("‚¨ÜÔ∏è Please upload at least one Meta Ads export file to start.")
    st.stop()


# ---------------------------------------------------------------------------
# Analysis sections
# ---------------------------------------------------------------------------
def render_funnel_decay(days_df: pd.DataFrame) -> None:
    """Render distribution of good days per funnel."""

    st.subheader("‚è≥ Funnel Decay Analysis")
    decay_df = compute_decay(days_df)
    if decay_df.empty:
        st.info("Not enough data to compute funnel decay.")
        return

    fig = px.box(
        decay_df,
        x="funnel",
        y="good_days_before_drop",
        title="Distribution of Good Days Before Drop by Funnel",
        points="all",
        color="funnel",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(decay_df.groupby("funnel")["good_days_before_drop"].describe())


def render_show_funnel_overview(days_df: pd.DataFrame) -> None:
    """Show spend and results by show and funnel."""

    st.subheader("üåç Show √ó Funnel Overview")
    required = {"funnel", "show", "amount_spent_(usd)", "impressions", "results", "cost_per_results"}
    if not required.issubset(days_df.columns):
        st.warning("Some required columns are missing from Days.csv export.")
        return

    overview = (
        days_df.groupby(["show", "funnel"]).agg(
            spend=("amount_spent_(usd)", "sum"),
            impressions=("impressions", "sum"),
            results=("results", "sum"),
            avg_cpr=("cost_per_results", "mean"),
        )
        .reset_index()
    )

    fig = px.scatter(
        overview,
        x="spend",
        y="results",
        size="impressions",
        color="funnel",
        facet_col="show",
        hover_data=["avg_cpr"],
        title="Spend vs Results by Show & Funnel",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(overview)


def render_time_of_day(days_time_df: pd.DataFrame) -> None:
    """Plot average cost per result by hour for each funnel."""

    st.subheader("üïí Time-of-Day Performance")
    if "time_of_day_(viewer's_time_zone)" not in days_time_df.columns or "cost_per_results" not in days_time_df.columns:
        st.info("No valid time-of-day data available.")
        return

    temp = days_time_df.copy()
    temp["hour"] = temp["time_of_day_(viewer's_time_zone)"].apply(parse_hour)
    if "funnel" not in temp.columns:
        temp["funnel"] = "Unclassified"

    def weighted_avg(group: pd.DataFrame) -> float:
        if "results" in group.columns and group["results"].sum() > 0:
            return float(np.average(group["cost_per_results"], weights=group["results"]))
        return float(group["cost_per_results"].mean())

    hour_perf = temp.groupby(["funnel", "hour"], dropna=True).apply(weighted_avg).reset_index(name="avg_cpr")
    if hour_perf.empty:
        st.info("Unable to calculate time-of-day metrics for the uploaded file.")
        return

    funnel_sel = st.selectbox("Funnel (Time)", sorted(hour_perf["funnel"].unique()))
    filtered = hour_perf[hour_perf["funnel"] == funnel_sel]

    fig = px.line(
        filtered,
        x="hour",
        y="avg_cpr",
        markers=True,
        title=f"Avg Cost per Result by Hour ({funnel_sel})",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(filtered)


def render_placement(days_pd_df: pd.DataFrame) -> None:
    """Evaluate placement performance within each funnel."""

    st.subheader("üì± Placement Performance")
    required = {"placement", "cost_per_results", "results", "amount_spent_(usd)", "funnel"}
    if not required.issubset(days_pd_df.columns):
        st.warning("Placement columns not found in Days + Placement + Device export.")
        return

    placement_perf = (
        days_pd_df.groupby(["funnel", "placement"]).agg(
            avg_cpr=("cost_per_results", "mean"),
            results=("results", "sum"),
            spend=("amount_spent_(usd)", "sum"),
        )
        .reset_index()
    )

    funnel_sel = st.selectbox("Funnel (Placement)", sorted(placement_perf["funnel"].unique()))
    filtered = placement_perf[placement_perf["funnel"] == funnel_sel]

    fig = px.bar(
        filtered.sort_values("avg_cpr"),
        x="placement",
        y="avg_cpr",
        color="spend",
        text="results",
        title=f"Placement Efficiency ({funnel_sel})",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(filtered)


def render_device(days_pd_df: pd.DataFrame) -> None:
    """Compare device performance within each funnel."""

    st.subheader("üíª Device Performance")
    required = {"impression_device", "cost_per_results", "results", "amount_spent_(usd)", "funnel"}
    if not required.issubset(days_pd_df.columns):
        st.warning("Device columns not found in Days + Placement + Device export.")
        return

    device_perf = (
        days_pd_df.groupby(["funnel", "impression_device"]).agg(
            avg_cpr=("cost_per_results", "mean"),
            results=("results", "sum"),
            spend=("amount_spent_(usd)", "sum"),
        )
        .reset_index()
    )

    funnel_sel = st.selectbox("Funnel (Device)", sorted(device_perf["funnel"].unique()))
    filtered = device_perf[device_perf["funnel"] == funnel_sel]

    fig = px.bar(
        filtered.sort_values("avg_cpr"),
        x="impression_device",
        y="avg_cpr",
        color="spend",
        text="results",
        title=f"Device Efficiency ({funnel_sel})",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(filtered)


# Trigger the different dashboard sections based on available uploads.
days_df = uploaded_dfs.get("days")
days_time_df = uploaded_dfs.get("days_time")
days_pd_df = uploaded_dfs.get("days_pd")

if days_df is not None:
    render_funnel_decay(days_df)
    render_show_funnel_overview(days_df)

if days_time_df is not None:
    render_time_of_day(days_time_df)

if days_pd_df is not None:
    render_placement(days_pd_df)
    render_device(days_pd_df)

st.success("‚úÖ Analyses complete. Explore interactively!")
